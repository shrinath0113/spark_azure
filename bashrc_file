# spark_azure
Installation steps apache hadoop,hive,hbase,pig and spark 

command : sudo nano ~/.bashrc

#JAVA VARIABLES START
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export PATH=$PATH:export PATH=$PATH:/usr/lib/jvm/java-11-openjdk-amd64/bin
#JAVA VARIABLES END

#HADOOP VARIABLES START
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_INSTALL=$HADOOP_HOME
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
export HADOOP_LOG_DIR=$HADOOP_HOME/logs
export PDSH_RCMD_TYPE=ssh
#HADOOP VARIABLES END

#HIVE VARIABLES START
export HIVE_HOME=/usr/local/apache-hive-2.3.9-bin
export PATH=$PATH:$HIVE_HOME/bin
export HIVE_CONF_DIR=$HIVE_HOME/conf
export CLASSPATH=$CLASSPATH:$HADOOP_HOME/lib/*:.
export CLASSPATH=$CLASSPATH:$HIVE_HOME/lib/*:.
#HIVE VARIABLES END

#DERBY VARIABLES START
export DERBY_HOME=/usr/local/db-derby-10.13.1.1-bin
export PATH=$PATH:$DERBY_HOME/bin
export CLASSPATH=$CLASSPATH:$DERBY_HOME/lib/derby.jar:$DERBY_HOME/lib/derbytools.jar
#DERBY VARIABLES END

#HBASE VARIABLES START
export HBASE_HOME=/usr/local/hbase-2.4.11
export PATH=$PATH:$HBASE_HOME/bin
export PATH=$PATH:$HBASE_HOME/sbin
export CLASSPATH=$CLASSPATH:$HBASE_HOME/lib*:.
#HBASE VARIABLES END

#PIG VARIABLES START
export PIG_HOME=/usr/local/pig-0.17.0
export PATH=$PATH:$PIG_HOME/bin
export PIG_CLASSPATH=$PIG_HOME/conf:$HADOOP_INSTALL/etc/hadoop/bin
export PIG_CONF_DIR=$PIG_HOME/conf
export PIG_CLASSPATH=$PIG_CONF_DIR
#PIG VARIABLES END

#SPARK VARIABLES START
export SPARK_HOME=/usr/local/spark-3.2.1-bin-hadoop3.2
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
#SPARK VARIABLES END

#PYTHON VARIABLES START
export PATH=$PATH:~/.local/bin
export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH
export PYSPARK_DRIVER_PYTHON="jupyter"
export PYSPARK_DRIVER_PYTHON_OPTS="notebook"
export PYSPARK_PYTHON=python3
#PYTHON VARIABLES END

command: source ~/.bashrc

sudo chown -R hduser:hadoop /usr/local/spark-3.2.1-bin-hadoop3.2/
sudo chown -R hduser:hadoop /usr/local/pig-0.17.0/
sudo chown -R hduser:hadoop /usr/local/nifi-1.15.3/
